{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理：RNN\n",
    "\n",
    "**自然言語処理**\n",
    "\n",
    "**RNNを活用**\n",
    "\n",
    "**計算結果が正確出来るように学習させる**\n",
    "\n",
    "**ライブラリはNmupyを活用**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:1.0574888630087576\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "24 + 53 = 238\n",
      "------------\n",
      "iters:100\n",
      "Loss:0.93840194387361\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "17 + 71 = 0\n",
      "------------\n",
      "iters:200\n",
      "Loss:1.0492934011172128\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "28 + 58 = 255\n",
      "------------\n",
      "iters:300\n",
      "Loss:0.987756614460655\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "83 + 70 = 0\n",
      "------------\n",
      "iters:400\n",
      "Loss:1.0257974017753393\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 1 0 1 0 1 0 0]\n",
      "92 + 120 = 255\n",
      "------------\n",
      "iters:500\n",
      "Loss:0.8739734461179863\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "95 + 28 = 255\n",
      "------------\n",
      "iters:600\n",
      "Loss:0.9541961251558709\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "71 + 115 = 174\n",
      "------------\n",
      "iters:700\n",
      "Loss:0.9158197635782452\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "70 + 89 = 255\n",
      "------------\n",
      "iters:800\n",
      "Loss:1.1588435420793362\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "6 + 122 = 255\n",
      "------------\n",
      "iters:900\n",
      "Loss:0.9997575046143101\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "35 + 70 = 1\n",
      "------------\n",
      "iters:1000\n",
      "Loss:1.013265153471509\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "116 + 33 = 0\n",
      "------------\n",
      "iters:1100\n",
      "Loss:0.9406473645889186\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "20 + 43 = 127\n",
      "------------\n",
      "iters:1200\n",
      "Loss:1.0578155988675784\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 1 0 0]\n",
      "102 + 118 = 0\n",
      "------------\n",
      "iters:1300\n",
      "Loss:0.995027091929322\n",
      "Pred:[1 0 0 1 0 1 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "75 + 95 = 150\n",
      "------------\n",
      "iters:1400\n",
      "Loss:0.9649956695612906\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "89 + 24 = 0\n",
      "------------\n",
      "iters:1500\n",
      "Loss:0.9234673962403493\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 1 0 1 1 1]\n",
      "83 + 68 = 131\n",
      "------------\n",
      "iters:1600\n",
      "Loss:0.993457906846273\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "79 + 94 = 0\n",
      "------------\n",
      "iters:1700\n",
      "Loss:1.0245847514282505\n",
      "Pred:[0 1 1 0 1 1 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "52 + 103 = 111\n",
      "------------\n",
      "iters:1800\n",
      "Loss:1.0704238541666096\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 1 1 0]\n",
      "119 + 103 = 0\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.7956955498590804\n",
      "Pred:[0 1 0 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "98 + 1 = 67\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.865091834892621\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[0 0 1 0 0 0 0 0]\n",
      "28 + 4 = 25\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.9277100966541435\n",
      "Pred:[0 0 0 0 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "4 + 87 = 9\n",
      "------------\n",
      "iters:2200\n",
      "Loss:0.7888929319761039\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "100 + 83 = 255\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.859434325766627\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "80 + 66 = 129\n",
      "------------\n",
      "iters:2400\n",
      "Loss:0.999867977740827\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 1 0 0 0 0]\n",
      "109 + 99 = 204\n",
      "------------\n",
      "iters:2500\n",
      "Loss:0.764324057053155\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "64 + 77 = 159\n",
      "------------\n",
      "iters:2600\n",
      "Loss:0.6668845321453464\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "30 + 89 = 255\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.7316720336735714\n",
      "Pred:[0 1 0 1 0 1 0 0]\n",
      "True:[0 1 0 1 0 1 0 0]\n",
      "48 + 36 = 84\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.7127654554264092\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 0 1 1]\n",
      "39 + 36 = 79\n",
      "------------\n",
      "iters:2900\n",
      "Loss:1.016373318683064\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "14 + 117 = 115\n",
      "------------\n",
      "iters:3000\n",
      "Loss:0.7068662807106668\n",
      "Pred:[1 0 1 0 1 1 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "54 + 117 = 175\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.7875054018093708\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "72 + 56 = 97\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.683946588724869\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "9 + 115 = 88\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.43441926947342285\n",
      "Pred:[0 1 0 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "8 + 89 = 65\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.6934317090080966\n",
      "Pred:[1 0 1 0 0 0 0 1]\n",
      "True:[1 1 0 0 0 0 0 1]\n",
      "68 + 125 = 161\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.26134075061283957\n",
      "Pred:[1 0 0 0 1 0 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "65 + 73 = 138\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.23126521664926936\n",
      "Pred:[0 0 1 0 0 1 1 0]\n",
      "True:[0 0 1 0 0 1 1 0]\n",
      "11 + 27 = 38\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.6110923644143894\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[0 0 1 1 1 0 1 1]\n",
      "6 + 53 = 25\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.20129452260587186\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 0 0 1 0 0]\n",
      "2 + 98 = 100\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.22733152485346467\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "68 + 118 = 186\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.22548428369683762\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "67 + 30 = 97\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.071357394542919\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "37 + 88 = 125\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.1480734846926444\n",
      "Pred:[0 1 0 0 0 1 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "59 + 12 = 71\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.047553134272554295\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "115 + 59 = 174\n",
      "------------\n",
      "iters:4400\n",
      "Loss:0.07946371419906975\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "34 + 119 = 153\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.05241500338069663\n",
      "Pred:[0 1 1 1 0 1 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "16 + 101 = 117\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.04125604805131188\n",
      "Pred:[0 1 0 0 0 0 1 1]\n",
      "True:[0 1 0 0 0 0 1 1]\n",
      "45 + 22 = 67\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.07823627201625478\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "96 + 2 = 98\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.010233243750947004\n",
      "Pred:[0 0 1 1 1 1 0 0]\n",
      "True:[0 0 1 1 1 1 0 0]\n",
      "5 + 55 = 60\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.0743386900060142\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "92 + 62 = 154\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.022311996231181075\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "19 + 106 = 125\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.005842091900669313\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 1 1 1 1 0 0]\n",
      "65 + 59 = 124\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.04613404996114299\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[1 1 0 1 1 1 0 0]\n",
      "110 + 110 = 220\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.007955611132506478\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "19 + 117 = 136\n",
      "------------\n",
      "iters:5400\n",
      "Loss:0.0036784700919025915\n",
      "Pred:[0 1 1 1 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "29 + 87 = 116\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.0046901291184239125\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "107 + 47 = 154\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.013591782658497134\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "32 + 123 = 155\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.011607062388642956\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "78 + 1 = 79\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.03508732237828541\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "126 + 40 = 166\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.01226292681940304\n",
      "Pred:[0 1 0 0 0 1 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "42 + 29 = 71\n",
      "------------\n",
      "iters:6000\n",
      "Loss:0.0027055010217493384\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "75 + 5 = 80\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.006713666593688647\n",
      "Pred:[0 0 1 1 0 0 0 1]\n",
      "True:[0 0 1 1 0 0 0 1]\n",
      "21 + 28 = 49\n",
      "------------\n",
      "iters:6200\n",
      "Loss:0.006578023736916657\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "65 + 16 = 81\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.009696410700440512\n",
      "Pred:[0 1 0 1 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "80 + 9 = 89\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.007055407163503128\n",
      "Pred:[1 0 1 0 0 1 0 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "89 + 76 = 165\n",
      "------------\n",
      "iters:6500\n",
      "Loss:0.0064260725138885815\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "39 + 92 = 131\n",
      "------------\n",
      "iters:6600\n",
      "Loss:0.007643764769036345\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "91 + 78 = 169\n",
      "------------\n",
      "iters:6700\n",
      "Loss:0.0016670267652910702\n",
      "Pred:[1 0 0 1 0 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "53 + 93 = 146\n",
      "------------\n",
      "iters:6800\n",
      "Loss:0.006336419312202363\n",
      "Pred:[0 1 1 0 0 1 1 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "66 + 37 = 103\n",
      "------------\n",
      "iters:6900\n",
      "Loss:0.02049100086515038\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "10 + 60 = 70\n",
      "------------\n",
      "iters:7000\n",
      "Loss:0.006484352110253474\n",
      "Pred:[1 0 1 0 0 0 1 1]\n",
      "True:[1 0 1 0 0 0 1 1]\n",
      "88 + 75 = 163\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.004294306273980528\n",
      "Pred:[1 1 0 1 0 0 0 1]\n",
      "True:[1 1 0 1 0 0 0 1]\n",
      "96 + 113 = 209\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.0010866350476370712\n",
      "Pred:[1 0 1 0 0 1 0 0]\n",
      "True:[1 0 1 0 0 1 0 0]\n",
      "115 + 49 = 164\n",
      "------------\n",
      "iters:7300\n",
      "Loss:0.005568605624343741\n",
      "Pred:[1 1 0 0 1 1 1 1]\n",
      "True:[1 1 0 0 1 1 1 1]\n",
      "96 + 111 = 207\n",
      "------------\n",
      "iters:7400\n",
      "Loss:0.0007330144211620962\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "9 + 109 = 118\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.012568458129557916\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "26 + 100 = 126\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:7600\n",
      "Loss:0.012423517613164476\n",
      "Pred:[1 0 0 0 0 1 0 0]\n",
      "True:[1 0 0 0 0 1 0 0]\n",
      "86 + 46 = 132\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.006641647201525642\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "40 + 97 = 137\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.005150869029812557\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "88 + 39 = 127\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.011971159915162762\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "52 + 20 = 72\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.0035035476232926368\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 1 1]\n",
      "69 + 122 = 191\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.005418344111963289\n",
      "Pred:[1 1 0 1 1 1 0 1]\n",
      "True:[1 1 0 1 1 1 0 1]\n",
      "94 + 127 = 221\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.0007469380516236227\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "15 + 113 = 128\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.0005997743234033775\n",
      "Pred:[0 1 0 0 0 0 1 0]\n",
      "True:[0 1 0 0 0 0 1 0]\n",
      "51 + 15 = 66\n",
      "------------\n",
      "iters:8400\n",
      "Loss:0.009238278610316347\n",
      "Pred:[0 0 0 1 0 0 1 0]\n",
      "True:[0 0 0 1 0 0 1 0]\n",
      "12 + 6 = 18\n",
      "------------\n",
      "iters:8500\n",
      "Loss:0.0037247924565798184\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "60 + 69 = 129\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.008592851849235965\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "76 + 92 = 168\n",
      "------------\n",
      "iters:8700\n",
      "Loss:0.0003993719863618981\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "51 + 123 = 174\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.007010678382967492\n",
      "Pred:[1 0 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "80 + 92 = 172\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.002291069062802176\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "65 + 64 = 129\n",
      "------------\n",
      "iters:9000\n",
      "Loss:0.0028959121880303977\n",
      "Pred:[1 1 0 0 0 0 0 1]\n",
      "True:[1 1 0 0 0 0 0 1]\n",
      "116 + 77 = 193\n",
      "------------\n",
      "iters:9100\n",
      "Loss:0.005937548129584902\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "10 + 82 = 92\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.00036220632769107985\n",
      "Pred:[1 1 0 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "111 + 83 = 194\n",
      "------------\n",
      "iters:9300\n",
      "Loss:0.0002088193233905185\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 0 0 1 0 0]\n",
      "3 + 97 = 100\n",
      "------------\n",
      "iters:9400\n",
      "Loss:0.00256468208422536\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "3 + 94 = 97\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.00697996651534907\n",
      "Pred:[1 0 0 1 0 1 0 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "86 + 62 = 148\n",
      "------------\n",
      "iters:9600\n",
      "Loss:0.00219847099432934\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "78 + 3 = 81\n",
      "------------\n",
      "iters:9700\n",
      "Loss:0.002521227226978129\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "32 + 95 = 127\n",
      "------------\n",
      "iters:9800\n",
      "Loss:0.00026489665282556117\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "31 + 67 = 98\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.002304939288574682\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "51 + 122 = 173\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1/(np.cosh(x) ** 2)\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化\n",
    "# He\n",
    "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
    "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "#学習\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.least_square(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_least_square(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "\n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "#学習をグラフ表示\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
